{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "available-acquisition",
   "metadata": {},
   "source": [
    "# FoNS Datathon 2021 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acknowledged-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "plt.rcParams['figure.figsize'] = (8,6)\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "union-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_descriptors = pd.read_csv(\"train_descriptors.csv\")\n",
    "train_mord3d = pd.read_csv(\"train_mord3d.csv\")\n",
    "train_morgan = pd.read_csv(\"train_morgan.csv\")\n",
    "train_rdk = pd.read_csv(\"train_rdk.csv\")\n",
    "\n",
    "train_crystals = pd.read_csv(\"train_crystals.csv\")\n",
    "train_distances = pd.read_csv(\"train_distances.csv\")\n",
    "train_centroid_distances = pd.read_csv(\"train_centroid_distances.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "electrical-climate",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_descriptors = pd.read_csv(\"test_descriptors.csv\")\n",
    "test_mord3d = pd.read_csv(\"test_mord3d.csv\")\n",
    "test_morgan = pd.read_csv(\"test_morgan.csv\")\n",
    "test_rdk = pd.read_csv(\"test_rdk.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-arizona",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "normal-marketing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13449, 984)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_descriptors_full = train_descriptors.iloc[:, 3:-2].dropna(axis= 1, how=\"any\")\n",
    "train_descriptors_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "central-commonwealth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3363, 984)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_descriptors_full = test_descriptors[train_descriptors_full.columns]\n",
    "test_descriptors_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "joint-champion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13449, 124) (3363, 124)\n"
     ]
    }
   ],
   "source": [
    "train_PCA = decomposition.PCA(n_components=.95)\n",
    "scaler_for_PCA = preprocessing.StandardScaler()\n",
    "train_descriptors_PCA = train_PCA.fit_transform(scaler_for_PCA.fit_transform(train_descriptors_full))\n",
    "test_descriptors_PCA = train_PCA.transform(scaler_for_PCA.transform(test_descriptors_full))\n",
    "print(train_descriptors_PCA.shape, test_descriptors_PCA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dying-african",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f717d185770>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "happy-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(train_descriptors_PCA).float()\n",
    "target = 'cell_volume'\n",
    "y = torch.tensor(train_crystals[target].values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "individual-necessity",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_in = x.shape[1]\n",
    "d_out = y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "pleased-latino",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(d_out,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "particular-triumph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3363, 984])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = torch.tensor(test_descriptors_full.values).float()\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "quarterly-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pca = torch.nn.Sequential(\n",
    "        torch.nn.Linear(d_in,2*d_in),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(2*d_in,1),\n",
    "        torch.nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "thrown-coverage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e83280f6b364894a4367a390e50ccfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 250.53619384765625\n",
      "199 235.1154327392578\n",
      "299 229.72683715820312\n",
      "399 226.78500366210938\n",
      "499 224.87969970703125\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.L1Loss()\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.Adam(model_pca.parameters(),lr=learning_rate)\n",
    "for t in tqdm(range(500)):\n",
    "    # Forward pass: compute predicted y by passing x to the model\n",
    "    y_pred = model_pca(x_pca)\n",
    "    \n",
    "    # compute and print loss\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "    \n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables it will update (which are the learnable\n",
    "    # weights of the model). This is because by default, gradients are\n",
    "    # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
    "    # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Backward pass: compute gradient of the loss with respect to model\n",
    "    # parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "scenic-samba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c68056fab14b71bde34761e1104cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 223.65011596679688\n",
      "199 222.5361328125\n",
      "299 221.5463409423828\n",
      "399 220.76123046875\n",
      "499 219.95713806152344\n",
      "599 219.3131866455078\n",
      "699 218.7624969482422\n",
      "799 218.2318572998047\n",
      "899 217.77935791015625\n",
      "999 217.29345703125\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.Adam(model_pca.parameters(),lr=learning_rate)\n",
    "for t in tqdm(range(1000)):\n",
    "    # Forward pass: compute predicted y by passing x to the model\n",
    "    y_pred = model_pca(x_pca)\n",
    "    \n",
    "    # compute and print loss\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "    \n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables it will update (which are the learnable\n",
    "    # weights of the model). This is because by default, gradients are\n",
    "    # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
    "    # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Backward pass: compute gradient of the loss with respect to model\n",
    "    # parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "tired-concept",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc8253e4fc248e69d5f70883d723ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 216.90133666992188\n",
      "199 216.56312561035156\n",
      "299 216.06517028808594\n",
      "399 215.7594451904297\n",
      "499 215.3126678466797\n",
      "599 214.90951538085938\n",
      "699 214.51931762695312\n",
      "799 214.1055908203125\n",
      "899 213.79388427734375\n",
      "999 213.3924102783203\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.Adam(model_pca.parameters(),lr=learning_rate)\n",
    "for t in tqdm(range(1000)):\n",
    "    # Forward pass: compute predicted y by passing x to the model\n",
    "    y_pred = model_pca(x_pca)\n",
    "    \n",
    "    # compute and print loss\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "    \n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables it will update (which are the learnable\n",
    "    # weights of the model). This is because by default, gradients are\n",
    "    # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
    "    # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Backward pass: compute gradient of the loss with respect to model\n",
    "    # parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "practical-grass",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_pca = torch.tensor(test_descriptors_PCA).float()\n",
    "predictions_pca = model_pca(x_test_pca).flatten().detach().numpy()\n",
    "np.savetxt(\"bonus_2_predictions.csv\", predictions_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-magazine",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
